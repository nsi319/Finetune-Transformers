{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15H0-gAnYVgOuImJweLxbBDvm_XUmi38W",
      "authorship_tag": "ABX9TyMLje94+q1K0zRIdW0TvNjo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsi319/Finetune-Transformers/blob/main/colab/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANTWUT2aTxhL"
      },
      "source": [
        "**Mount Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DuuKlveTnP6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2jQibUJUWFZ"
      },
      "source": [
        "**Clone the repository and place it in your drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWOzpMYqrCZM"
      },
      "source": [
        "!git clone https://github.com/nsi319/Finetune-Transformers.git /content/drive/MyDrive/Finetune/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK2kcMYNOp8r"
      },
      "source": [
        "**Install packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLG0rEUkq0x5"
      },
      "source": [
        "# Huggingface Transformer library for Trainer API, Data Arguments classes\n",
        "!pip install transformers \n",
        "# For using available datasets such as xsum, cnn-dailymail\n",
        "!pip install datasets\n",
        "# For computing metrics and evaluating summaries    \n",
        "!pip install rouge_score  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf-r-KEu2dz2"
      },
      "source": [
        "paths = {}\n",
        "paths['train_file'] = \"/content/drive/MyDrive/Finetune/run.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig4uU0kWMcmO"
      },
      "source": [
        "**Include custom data or use test data placed at data/**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb5Em1pFslBZ"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Use small dataset placed at data/\n",
        "\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/Finetune/data/news_summary_train_small.csv\", encoding='latin-1')\n",
        "df_train = df_train[['Text','Summary']]\n",
        "print(df_train.head())\n",
        "\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Finetune/data/news_summary_valid_small.csv\", encoding='latin-1')\n",
        "df_test = df_test[['Text','Summary']]\n",
        "print(df_test.head())\n",
        "\n",
        "# OR\n",
        "\n",
        "# Perform custom train test split\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXMF6K414esM"
      },
      "source": [
        "paths['train_data_file'] = \"/content/drive/MyDrive/Finetune/data/news_summary_train_small.csv\"\n",
        "paths['test_data_file'] = \"/content/drive/MyDrive/Finetune/data/news_summary_valid_small.csv\"\n",
        "paths['output_directory'] = \"/content/drive/MyDrive/Finetune/data/output\"\n",
        "print(paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsFLnSjzWivn"
      },
      "source": [
        "**Train and Evaluate the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzjmnaPtTTrQ"
      },
      "source": [
        "More information regarding different arguments to run.py\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjD3UoZrRy9Z"
      },
      "source": [
        "!python /content/drive/MyDrive/Finetune/run.py --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COe46Ys4TZ8n"
      },
      "source": [
        "**Running finetuning script**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITcHWLMsrtfN"
      },
      "source": [
        "# Use the values from the dictionary \n",
        "\n",
        "#   ARGUMENT NAME        CORRESPONDING DICTIONARY KEY\n",
        "# python file to run  =>    train_file\n",
        "# train_file          =>    train_data_file\n",
        "# validation_file     =>    test_data_file\n",
        "# output_dir          =>    output_directory\n",
        "\n",
        "\n",
        "# This example finetunes pre-trained model bart-base\n",
        "# Other seq2seq models such as t5, pegasus, mbart can also be finetuned \n",
        "\n",
        "!python /content/drive/MyDrive/Finetune/run.py  \\\n",
        "    --model_name_or_path facebook/bart-base \\\n",
        "    --task summarization \\\n",
        "    --train_file /content/drive/MyDrive/Finetune/data/news_summary_train_small.csv \\\n",
        "    --validation_file /content/drive/MyDrive/Finetune/data/news_summary_valid_small.csv \\\n",
        "    --text_column Text \\\n",
        "    --summary_column Summary \\\n",
        "    --output_dir /content/drive/MyDrive/Finetune/output \\\n",
        "    --overwrite_output_dir \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --num_beams=3 \\\n",
        "    --min_summ_length=100 \\\n",
        "    --max_summ_length=250 \\\n",
        "    --length_penalty=1.0 \\\n",
        "    --per_device_train_batch_size=4 \\\n",
        "    --per_device_eval_batch_size=4 \\\n",
        "    --predict_with_generate \n",
        "\n",
        "\"\"\"   \n",
        "Output files description:\n",
        "\n",
        "n-test_results.csv     =>  Evaluation results consisting of Generated Summary, Actual Summary, F Score and Precision Score\n",
        "config.json            =>  Model configurations \n",
        "evaluation_scores.txt  =>  Evaluation results consisting of mean precision and fmeasure score along with Best_n and Worst_n summaries \n",
        "pytorch_model.bin      =>  Finetuned model\n",
        "tokenizer_config.json  =>  Tokenizer configurations\n",
        "\n",
        "\"\"\"\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}